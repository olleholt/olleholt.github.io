[
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "blog",
    "section": "",
    "text": "AQI Analysis in Santa Barbara\n\n\nTime series analysis for Air Quality Index before, during, and after Thomas Fire.\n\n\n\nOlivia Holt\n\n\n\n\n\n\n\n\n\n\n\n\nparquet and GeoParquet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOlivia Holt\n\n\n\nQuarto\n\n\nR\n\n\nMEDS\n\n\n\neds222\n\n\n\nOlivia Holt\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOlivia Holt\n\n\n\nQuarto\n\n\nR\n\n\nMEDS\n\n\n\nEDS242 Final Blog\n\n\n\nOlivia Holt\n\n\nDec 10, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2023-11-06-myfirstpost/index.html",
    "href": "blog/2023-11-06-myfirstpost/index.html",
    "title": "Olivia Holt",
    "section": "",
    "text": "Lake Tahoe water clarity has been measured since 1967.\nClarity is measured as depth using a Secchi disk.\nCalifornia and Nevada, are actively working to restore lake clarity to its historic 97.4 feet.\nFactors known to influence year-to-year changes in clarity include the magnitude of runoff, the warming of the lake surface and the depth to which the lake mixes in the previous winter."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blog/trial-python-render/contextily-and-parquet.html",
    "href": "blog/trial-python-render/contextily-and-parquet.html",
    "title": "parquet and GeoParquet",
    "section": "",
    "text": "** Apachece Parquet**\n\nimport geopandas\nimport matplotlib.pyplot as plt\n\nimport pystac_client\nimport planetary_computer\n\nimport contextily as ctx # for adding basemaps\n\nModuleNotFoundError: No module named 'contextily'\n\n\n\ncatalog = pystac_client.client.open(\n    \"\",\n    modifier = planetary_computer.sign_inplace,\n)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Olivia Holt",
    "section": "",
    "text": "B.S. Environmental Engineering (2020), Colorado School of Mines\nM.S. Hydrologic Science & Engineering (2021), Colorado School of Mines"
  },
  {
    "objectID": "index.html#hi",
    "href": "index.html#hi",
    "title": "Olivia Holt",
    "section": "",
    "text": "Bio here\nB.S. Environmental Engineering (2020), Colorado School of Mines\nM.S. Hydrologic Science & Engineering (2021), Colorado School of Mines"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Olivia Holt",
    "section": "Experience",
    "text": "Experience\nHydrologic Technician for the U.S. Geological Survey\nAssistant Water Resource Engineer for Confluence Engineering Solutions"
  },
  {
    "objectID": "blog/eds242-blog/eds242-finalblogpost.html",
    "href": "blog/eds242-blog/eds242-finalblogpost.html",
    "title": "Olivia Holt",
    "section": "",
    "text": "The escalating threat of climate change has prompted the exploration of innovative solutions, and artificial intelligence (AI) has emerged as a potential ally against environmental problems.\nThe adoption of AI, particularly in the form of machine learning applications, offers promising avenues for combating climate change. AI can contribute to data collection, processing, and analysis related to temperature change, carbon emissions, weather predictions, and the effects of extreme weather events. Additionally, AI applications can optimize energy consumption, transform transportation for efficiency and reduced emissions, monitor ecosystems, predict droughts, enable precision agriculture, and enhance recycling processes. Governments and tech companies alike, including Microsoft, Amazon, and Google, have begun investing in AI programs to combat climate change, recognizing the technology’s potential to revolutionize environmental stewardship.\n\n\nOne company currently working on environmental issues with the use of AI and machine learning is Climate Change AI (CCAI). Stated on their website as part of their guiding principles is, “Diversity, inclusion, and equity are central to the advancement of society in general, and moreover fundamental to progress in addressing climate change. Where possible, it is important that work in climate change and machine learning attempt to address the structural inequities that exist in today’s society” (CCAI). It is crucial for companies to not only address ethical considerations in their statements but to also follow through in their work.\n\n\n\n\n\n\nThe US National Oceanic and Atmospheric Administration leverages artificial intelligence to enhance the accuracy of forecasts for severe weather occurrences, including hurricanes, and to extract valuable insights from diverse datasets.\nScientists at NYU, supported by a $10 million grant from Schmidt Futures, are dedicated to refining climate-change predictions through the enhancement of climate simulations, employing artificial intelligence methodologies.\nThe Green Horizons initiative by IBM, a research endeavor, leverages the capabilities of AI and the Internet of Things (IoT) for the analysis of climate change data. With machine learning, the system assimilates information from diverse sources, including meteorological satellites and traffic cameras, to refine its predictive models. It can predict pollution levels with a 72-hour lead time, offering precise insights on the origin and likely trajectory of pollution down to the nearest kilometer.\n\n\n\n\n\nAccording to technology entrepreneur Ewan Kirk, “Using UAVs to effectively monitor vegetation and land over large areas will help scientists and researchers to create large data sets helping them understand how climate change is affecting some of the world’s most critical resources”. Drones are one of the most efficient ways to collect data from remote regions, and gather information on ecological health.\n\n\n\n\n\nDespite the potential benefits, the application of AI in addressing climate change presents numerous ethical challenges. One of the foremost concerns is the significant energy consumption associated with AI, particularly in training complex models. Data centers that support AI operations often demand substantial electricity, which contributes to environmental issues. The production of electronic devices and AI technologies also involves resource-intensive processes, raising questions about the environmental footprint of the very tools intended to mitigate climate change.\nThe paper “AI for climate: freedom, justice, and other ethical and political Challenges’’ by Mark Coeckelbergh emphasizes the need for increased awareness about the ethical implications of AI usage. They underscore the importance of interdisciplinary education that integrates ethical considerations into technology-related fields. The call for more research highlights the necessity for an interdisciplinary approach to education and transparency within the AI development community.\nThe political implications of employing AI for climate action are complex, with significant emphasis on issues related to freedom and governance. The paper delineates two primary options: the use of AI to influence human behavior through nudging and the “Green Leviathan” approach of AI-driven governance. Nudging, a concept that requires altering the decision-making environment to steer individuals toward climate-friendly choices, raises concerns about preserving human autonomy and rationality. While nudging does not coerce individuals, it influences choices, potentially undermining the principles of autonomy and rational decision-making.\nOn the other hand, the idea of AI-driven governance entails regulating human behavior on a global scale to achieve climate goals. This approach, while effective, poses a threat to individual freedom through coercion. The paper draws parallels to the political philosophy of Thomas Hobbes, who advocated for a Leviathan to prevent chaos, highlighting the ethical dilemma between sacrificing freedom for the greater good or finding a middle ground that preserves both.\nThe global perspective on climate change introduces a complex framework of justice-related challenges. Not all communities and nations are equally vulnerable to climate change, which underlines concerns about justice and fairness. It is necessary to consider the differential impact of climate change measures on various communities, generations, and regions. This introduces questions of global justice, highlighting the ethical responsibility to evaluate AI interventions based on their effects on different populations and geographical locations.\nThe intergenerational dimension of climate change raises ethical questions about who should bear the costs of addressing a crisis that spans multiple generations. As a current graduate student, this prompts reflection on the ethical implications of the actions taken today on the well-being of future generations.\nThe use of AI for climate action holds great potential, but it requires a conscientious approach to ethical and political challenges. Engaging with these issues involves advocating for interdisciplinary education that integrates ethical considerations into technological development. Additionally, fostering transparency within the AI community and contributing to public discussions about the ethical implications of AI applications are crucial steps in navigating the complex terrain of using AI for climate issues. The responsibility extends beyond individual actions to collective efforts that shape the ethical and political landscape of AI in the pursuit of a sustainable and just future.\n\n\n\nCoeckelbergh, M. (2020). AI for climate: Freedom, justice, and other ethical and political challenges. AI and Ethics, 1(1), 67–72. https://doi.org/10.1007/s43681-020-00007-2\nClimate Change AI. (n.d.). https://www.climatechange.ai/about\nMinevich, M. (2023, October 5). AI champions Driving New Industry Solutions for Climate Change. Forbes. https://www.forbes.com/sites/markminevich/2021/03/31/ai-champions-driving-new-industry-solutions-for-climate-change/?sh=4ad1bc274f66"
  },
  {
    "objectID": "blog/eds242-blog/eds242-finalblogpost.html#ai-and-machine-learning-in-climate-analysis",
    "href": "blog/eds242-blog/eds242-finalblogpost.html#ai-and-machine-learning-in-climate-analysis",
    "title": "Olivia Holt",
    "section": "",
    "text": "The escalating threat of climate change has prompted the exploration of innovative solutions, and artificial intelligence (AI) has emerged as a potential ally against environmental problems.\nThe adoption of AI, particularly in the form of machine learning applications, offers promising avenues for combating climate change. AI can contribute to data collection, processing, and analysis related to temperature change, carbon emissions, weather predictions, and the effects of extreme weather events. Additionally, AI applications can optimize energy consumption, transform transportation for efficiency and reduced emissions, monitor ecosystems, predict droughts, enable precision agriculture, and enhance recycling processes. Governments and tech companies alike, including Microsoft, Amazon, and Google, have begun investing in AI programs to combat climate change, recognizing the technology’s potential to revolutionize environmental stewardship.\n\n\nOne company currently working on environmental issues with the use of AI and machine learning is Climate Change AI (CCAI). Stated on their website as part of their guiding principles is, “Diversity, inclusion, and equity are central to the advancement of society in general, and moreover fundamental to progress in addressing climate change. Where possible, it is important that work in climate change and machine learning attempt to address the structural inequities that exist in today’s society” (CCAI). It is crucial for companies to not only address ethical considerations in their statements but to also follow through in their work.\n\n\n\n\n\n\nThe US National Oceanic and Atmospheric Administration leverages artificial intelligence to enhance the accuracy of forecasts for severe weather occurrences, including hurricanes, and to extract valuable insights from diverse datasets.\nScientists at NYU, supported by a $10 million grant from Schmidt Futures, are dedicated to refining climate-change predictions through the enhancement of climate simulations, employing artificial intelligence methodologies.\nThe Green Horizons initiative by IBM, a research endeavor, leverages the capabilities of AI and the Internet of Things (IoT) for the analysis of climate change data. With machine learning, the system assimilates information from diverse sources, including meteorological satellites and traffic cameras, to refine its predictive models. It can predict pollution levels with a 72-hour lead time, offering precise insights on the origin and likely trajectory of pollution down to the nearest kilometer.\n\n\n\n\n\nAccording to technology entrepreneur Ewan Kirk, “Using UAVs to effectively monitor vegetation and land over large areas will help scientists and researchers to create large data sets helping them understand how climate change is affecting some of the world’s most critical resources”. Drones are one of the most efficient ways to collect data from remote regions, and gather information on ecological health.\n\n\n\n\n\nDespite the potential benefits, the application of AI in addressing climate change presents numerous ethical challenges. One of the foremost concerns is the significant energy consumption associated with AI, particularly in training complex models. Data centers that support AI operations often demand substantial electricity, which contributes to environmental issues. The production of electronic devices and AI technologies also involves resource-intensive processes, raising questions about the environmental footprint of the very tools intended to mitigate climate change.\nThe paper “AI for climate: freedom, justice, and other ethical and political Challenges’’ by Mark Coeckelbergh emphasizes the need for increased awareness about the ethical implications of AI usage. They underscore the importance of interdisciplinary education that integrates ethical considerations into technology-related fields. The call for more research highlights the necessity for an interdisciplinary approach to education and transparency within the AI development community.\nThe political implications of employing AI for climate action are complex, with significant emphasis on issues related to freedom and governance. The paper delineates two primary options: the use of AI to influence human behavior through nudging and the “Green Leviathan” approach of AI-driven governance. Nudging, a concept that requires altering the decision-making environment to steer individuals toward climate-friendly choices, raises concerns about preserving human autonomy and rationality. While nudging does not coerce individuals, it influences choices, potentially undermining the principles of autonomy and rational decision-making.\nOn the other hand, the idea of AI-driven governance entails regulating human behavior on a global scale to achieve climate goals. This approach, while effective, poses a threat to individual freedom through coercion. The paper draws parallels to the political philosophy of Thomas Hobbes, who advocated for a Leviathan to prevent chaos, highlighting the ethical dilemma between sacrificing freedom for the greater good or finding a middle ground that preserves both.\nThe global perspective on climate change introduces a complex framework of justice-related challenges. Not all communities and nations are equally vulnerable to climate change, which underlines concerns about justice and fairness. It is necessary to consider the differential impact of climate change measures on various communities, generations, and regions. This introduces questions of global justice, highlighting the ethical responsibility to evaluate AI interventions based on their effects on different populations and geographical locations.\nThe intergenerational dimension of climate change raises ethical questions about who should bear the costs of addressing a crisis that spans multiple generations. As a current graduate student, this prompts reflection on the ethical implications of the actions taken today on the well-being of future generations.\nThe use of AI for climate action holds great potential, but it requires a conscientious approach to ethical and political challenges. Engaging with these issues involves advocating for interdisciplinary education that integrates ethical considerations into technological development. Additionally, fostering transparency within the AI community and contributing to public discussions about the ethical implications of AI applications are crucial steps in navigating the complex terrain of using AI for climate issues. The responsibility extends beyond individual actions to collective efforts that shape the ethical and political landscape of AI in the pursuit of a sustainable and just future.\n\n\n\nCoeckelbergh, M. (2020). AI for climate: Freedom, justice, and other ethical and political challenges. AI and Ethics, 1(1), 67–72. https://doi.org/10.1007/s43681-020-00007-2\nClimate Change AI. (n.d.). https://www.climatechange.ai/about\nMinevich, M. (2023, October 5). AI champions Driving New Industry Solutions for Climate Change. Forbes. https://www.forbes.com/sites/markminevich/2021/03/31/ai-champions-driving-new-industry-solutions-for-climate-change/?sh=4ad1bc274f66"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Olivia Holt",
    "section": "",
    "text": "B.S. Environmental Engineering (2020), Colorado School of Mines\nM.S. Hydrologic Science & Engineering (2021), Colorado School of Mines"
  },
  {
    "objectID": "blog/2023-11-06-myfirstpost/index.html#background",
    "href": "blog/2023-11-06-myfirstpost/index.html#background",
    "title": "Olivia Holt",
    "section": "",
    "text": "Lake Tahoe water clarity has been measured since 1967.\nClarity is measured as depth using a Secchi disk.\nCalifornia and Nevada, are actively working to restore lake clarity to its historic 97.4 feet.\nFactors known to influence year-to-year changes in clarity include the magnitude of runoff, the warming of the lake surface and the depth to which the lake mixes in the previous winter."
  },
  {
    "objectID": "blog/2023-11-06-myfirstpost/index.html#analysis",
    "href": "blog/2023-11-06-myfirstpost/index.html#analysis",
    "title": "Olivia Holt",
    "section": "Analysis",
    "text": "Analysis\n\nSimple Linear Regression model\nCall: lm(formula = Secchi_Ave ~ avg_Chla, data = joined)\nResiduals:     Min      1Q  Median      3Q     Max\n-12.144  -2.554  -0.314   2.535  18.834\nCoefficients:             Estimate Std. Error t value             Pr(&gt;|t|)     (Intercept)  23.0601     0.4660  49.487 &lt; 0.0000000000000002 ***\navg_Chla     -1.9169     0.6615  -2.898              0.00397 **\n--- Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  Residual standard error: 4.258 on 385 degrees of freedom Multiple R-squared:  0.02135,  Adjusted R-squared:  0.01881  F-statistic: 8.398 on 1 and 385 DF,  p-value: 0.003971\n\n\n\n\n\n\n\nTime Series Analysis\nseasonality\noverall decline in in secchi depth"
  },
  {
    "objectID": "blog/2023-11-06-myfirstpost/index.html#takeaways",
    "href": "blog/2023-11-06-myfirstpost/index.html#takeaways",
    "title": "Olivia Holt",
    "section": "Takeaways",
    "text": "Takeaways\n\nChlorophyll only shows a small influence on the variance of clarity\nlook at things that interact with chl\n\ndiatoms/zooplankton\n\n\n\nReferences\nToy, A. N. (2023, April 10). Clarity/Secchi. Tahoe Environmental Research Center. https://tahoe.ucdavis.edu/secchi#:~:text=Clarity%20sinks%20in&text=In%202022%2C%20Lake%20Tahoe’s%20average,Secchi%20depth%20was%2080.6%20feet.\nWatanabe, Shohei; Schladow, Geoffrey (2022). Limnological data for Lake Tahoe seasonal and long-term clarity trend analysis report [Dataset]. Dryad. https://doi.org/10.25338/B83P8B"
  },
  {
    "objectID": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#importing-libraries",
    "href": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#importing-libraries",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Code\n#importing libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches # for creating legends\n\nimport xarray as xr\nimport rioxarray as rioxr\nimport geopandas as gpd\n\nfrom rasterio.features import rasterize #for rasterizing polygons\nfrom shapely.geometry import box\nfrom shapely.geometry import Point\n\n\nModuleNotFoundError: No module named 'xarray'"
  },
  {
    "objectID": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#import-data",
    "href": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#import-data",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "loading in the both the AQI data and the california fire perimeter data\n\n\nCode\n#read in aqi 2017 data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\")\n\n#read in aqi 2018 data\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\")\n\n# importing california fire perimeter data\nca = gpd.read_file('data/California_Fire_Perimeters_2017.shp')\n\n#reading in the .nc file\nlandcover_fp = os.path.join(os.getcwd(),'data','landsat8-2018-01-26-sb-simplified.nc')\nlandcover = rioxr.open_rasterio(landcover_fp)"
  },
  {
    "objectID": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#data-exploration",
    "href": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#data-exploration",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Code\n# looking at the head of the data\nca.head()\n\n#looking at the shape\nca.shape\n\n#looking at the head of the data\nlandcover.head()\n\n#looking at the shape of landcover\nlandcover.rio.shape\n\n#looking at the dimensions of the landcover data\nlandcover.dims\n\n#view first 5 columns of aqi 2017 data\naqi_17.head()\n\n#view first 5 columns of aqi 2018 data\naqi_18.head()\n\n#view columns of aqi 2017 data\naqi_17.columns\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')"
  },
  {
    "objectID": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#cleaningorganizing",
    "href": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#cleaningorganizing",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Tidying the air quality data by combining both dataset for easier use. The raster data contains additionals bands that are not needed for this analysis. These bands were removed to improve processing.\n\n\nCode\n#combine both data sets into one dataset unsing concat\naqi = pd.concat([aqi_17,aqi_18])\n\n# re-assign the column names - .str.lower() makes them lower case\naqi.columns = aqi.columns.str.lower()\n\n#  re-assign the column names again - .str.replace(' ','_') replaces the space for _\naqi.columns = aqi.columns.str.replace(' ','_')\n\n\n\n\nCode\n#dropping the bands to make a 2d data set in order to plot it\nlandcover = landcover.squeeze().drop('band')\n\n# checking to see if the crs's match\nca.crs == landcover.rio.crs\n\n#set landcover crs to ca crs, crs='EPSG:3857'\nca = ca.to_crs(landcover.rio.crs)"
  },
  {
    "objectID": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#analysis",
    "href": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#analysis",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "Filtering the air quality to the area of interest for analysis. Converting the data column to a datetime object will help when plotting the data.\n\n\nCode\n#selecting rows that equal 'santa barbara' in the county_name column\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n\n#removing the four specified columns\naqi_sb = aqi_sb.drop(columns = ['state_name','county_name','state_code', 'county_code'])\n\n# covert aqi_sb.DATE column to timedate objects\npd.to_datetime(aqi_sb.date)\n\n# convert DATE column from string to timestamps\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n\n#update the index tp the date column\naqi_sb = aqi_sb.set_index(aqi_sb.date)\n\n# and we get a pd.Series as ouput\naqi_sb.aqi.rolling('5D').mean()\n\n#adding a new column named 'five_day_average' into the aqi_sb dataframe\n#finding the mean of the AQI over a 5 day rolling window and inputting those values into the new column\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean()\n\n\n\n\nCode\n#selecting the thomas fire from the california fire 2017 dataset\nthomas_fire = ca[ca['FIRE_NAME'] == 'THOMAS']"
  },
  {
    "objectID": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#final-plotting",
    "href": "blog/Thomas_Fire_analysis/hw4-task3_blog.html#final-plotting",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "The final air quality plot for Santa Barbara county, impacted by the Thomas Fire. This shows the daily AQI and a 5 day average. The next plot is a map of the fire perimeter in Southern California.\n\n\nCode\n#plotting the AQI and the rolling averaged AQI over 5 days against eachother\naqi_sb.plot(y= ['aqi','five_day_average'], title='AQI vs 5 Day Averages', color = ['purple', 'green'] )\n\n\n&lt;AxesSubplot:title={'center':'AQI vs 5 Day Averages'}, xlabel='date'&gt;\n\n\n\n\n\n\n\nCode\n# setting up a plot\nfig, ax = plt.subplots()\n\n# plotting the thomas fire on top of the landover plot\nthomas_fire.plot(ax=ax,\n                color = \"darksalmon\",\n                edgecolor= \"black\")\nlandcover[['swir22','nir08','red']].to_array().plot.imshow(robust = True)  #landcover plot\n\n#setting the title name\nax.set_title('Thomas Fire in Santa Barbara County',  fontsize=14)\n\n\nText(0.5, 1.0, 'Thomas Fire in Santa Barbara County')"
  },
  {
    "objectID": "blog/Thomas_Fire_analysis/hw4-task3_blog.html",
    "href": "blog/Thomas_Fire_analysis/hw4-task3_blog.html",
    "title": "AQI Analysis in Santa Barbara",
    "section": "",
    "text": "To visualize the impact on the Air Quality Index Thomas Fire in Santa Barbara County and to create a false color image showing the fire scar of the Thomas fire in 2017.\n\n\n\n\nData wrangling and exploration\nGeospatial data wrangling\nCreating a plot for AQI through 2017\nCreating and customizing a map\n\n\n\n\nDataset 1\nAir Quality Index (AQI) data from the US Environmental Protection Agency.\nDataset 2\nA simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite.\nThis data was accessed and pre-processed in the Microsoft Planetary Computer to remove data outside land and coarsen the spatial resolution (Landsat Collection in MPC). Data should be used for visualization purposes only.\nDataset 3\nA shapefile of fire perimeters in California during 2017. The complete file can be accessed in the CA state geoportal.\n\n\n\nAirNow. (2021b). Air Quality Index (AQI) Basics. Retrieved from www.airnow.gov website: https://www.airnow.gov/aqi/aqi-basics/\nWikipedia Contributors. (2019, October 6). Thomas Fire. Retrieved from Wikipedia website: https://en.wikipedia.org/wiki/Thomas_Fire\nCalifornia Fire Perimeters (all). (n.d.). Retrieved November 29, 2023, from gis.data.ca.gov website: https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about\nMicrosoft Planetary Computer. Planetary Computer. (n.d.). https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2))\n\n\n\n\n\nCode\n#importing libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches # for creating legends\n\nimport xarray as xr\nimport rioxarray as rioxr\nimport geopandas as gpd\n\nfrom rasterio.features import rasterize #for rasterizing polygons\nfrom shapely.geometry import box\nfrom shapely.geometry import Point\n\n\nModuleNotFoundError: No module named 'xarray'\n\n\n\n\n\nloading in the both the AQI data and the california fire perimeter data\n\n\nCode\n#read in aqi 2017 data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\")\n\n#read in aqi 2018 data\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\")\n\n# importing california fire perimeter data\nca = gpd.read_file('data/California_Fire_Perimeters_2017.shp')\n\n#reading in the .nc file\nlandcover_fp = os.path.join(os.getcwd(),'data','landsat8-2018-01-26-sb-simplified.nc')\nlandcover = rioxr.open_rasterio(landcover_fp)\n\n\n\n\n\nTidying the air quality data by combining both dataset for easier use. The raster data contains additionals bands that are not needed for this analysis. These bands were removed to improve processing.\n\n\nCode\n#combine both data sets into one dataset unsing concat\naqi = pd.concat([aqi_17,aqi_18])\n\n# re-assign the column names - .str.lower() makes them lower case\naqi.columns = aqi.columns.str.lower()\n\n#  re-assign the column names again - .str.replace(' ','_') replaces the space for _\naqi.columns = aqi.columns.str.replace(' ','_')\n\n\n\n\nCode\n#dropping the bands to make a 2d data set in order to plot it\nlandcover = landcover.squeeze().drop('band')\n\n# checking to see if the crs's match\nca.crs == landcover.rio.crs\n\n#set landcover crs to ca crs, crs='EPSG:3857'\nca = ca.to_crs(landcover.rio.crs)\n\n\n\n\n\nFiltering the air quality to the area of interest for analysis. Converting the data column to a datetime object will help when plotting the data.\n\n\nCode\n#selecting rows that equal 'santa barbara' in the county_name column\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n\n#removing the four specified columns\naqi_sb = aqi_sb.drop(columns = ['state_name','county_name','state_code', 'county_code'])\n\n# covert aqi_sb.DATE column to timedate objects\npd.to_datetime(aqi_sb.date)\n\n# convert DATE column from string to timestamps\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n\n#update the index tp the date column\naqi_sb = aqi_sb.set_index(aqi_sb.date)\n\n# and we get a pd.Series as ouput\naqi_sb.aqi.rolling('5D').mean()\n\n#adding a new column named 'five_day_average' into the aqi_sb dataframe\n#finding the mean of the AQI over a 5 day rolling window and inputting those values into the new column\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean()\n\n\n\n\nCode\n#selecting the thomas fire from the california fire 2017 dataset\nthomas_fire = ca[ca['FIRE_NAME'] == 'THOMAS']\n\n\n\n\n\nThe final air quality plot for Santa Barbara county, impacted by the Thomas Fire. This shows the daily AQI and a 5 day average. The next plot is a map of the fire perimeter in Southern California.\n\n\nCode\n#plotting the AQI and the rolling averaged AQI over 5 days against eachother\naqi_sb.plot(y= ['aqi','five_day_average'], title='AQI vs 5 Day Averages', color = ['purple', 'green'] )\n\n\n&lt;AxesSubplot:title={'center':'AQI vs 5 Day Averages'}, xlabel='date'&gt;\n\n\n\n\n\n\n\nCode\n# setting up a plot\nfig, ax = plt.subplots()\n\n# plotting the thomas fire on top of the landover plot\nthomas_fire.plot(ax=ax,\n                color = \"darksalmon\",\n                edgecolor= \"black\")\nlandcover[['swir22','nir08','red']].to_array().plot.imshow(robust = True)  #landcover plot\n\n#setting the title name\nax.set_title('Thomas Fire in Santa Barbara County',  fontsize=14)\n\n\nText(0.5, 1.0, 'Thomas Fire in Santa Barbara County')"
  }
]